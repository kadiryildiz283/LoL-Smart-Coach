import json
import os
import time
import random
import re
from bs4 import BeautifulSoup
from curl_cffi import requests

# --- AYARLAR ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
OUTPUT_DIR = os.path.join(DATA_DIR, "output")
INPUT_FILE = os.path.join(DATA_DIR, "sampiyon_listesi.json")

# BÃ¶lge ayarÄ± (Linkteki 'iron' kÄ±smÄ± iÃ§in)
REGION = "iron"  # emerald, platinum, diamond, master vb. yapabilirsin

# URL DÃ¼zeltmeleri
URL_FIXES = {
    "nunu & willump": "nunu",
    "renata glasc": "renata",
    "dr. mundo": "drmundo",
    "bel'veth": "belveth",
    "kai'sa": "kaisa",
    "kha'zix": "khazix",
    "kog'maw": "kogmaw",
    "k'sante": "ksante",
    "leblanc": "leblanc",
    "lee sin": "leesin",
    "master yi": "masteryi",
    "miss fortune": "missfortune",
    "tahm kench": "tahmkench",
    "twisted fate": "twistedfate",
    "xin zhao": "xinzhao",
    "rek'sai": "reksai",
    "jarvan iv": "jarvaniv",
    "aurelion sol": "aurelionsol",
    "wukong": "monkeyking"
}

class LoLScraper:
    def __init__(self):
        # GerÃ§ekÃ§i tarayÄ±cÄ± taklidi
        self.session = requests.Session(impersonate="chrome120")
        
    def get_soup(self, url):
        for attempt in range(3):
            try:
                response = self.session.get(url, timeout=15)
                if response.status_code == 200:
                    return BeautifulSoup(response.content, 'lxml')
                elif response.status_code == 429:
                    print(f"   ğŸ›‘ 429 Hata (IP Ban Riski). 60sn soÄŸuma...")
                    time.sleep(60)
                else:
                    time.sleep(2)
            except Exception as e:
                print(f"   âš ï¸ BaÄŸlantÄ± hatasÄ±: {e}")
                time.sleep(2)
        return None

bot = LoLScraper()

def sanitize_name(name):
    """Ä°smi URL formatÄ±na Ã§evirir."""
    name_lower = name.lower()
    if name_lower in URL_FIXES:
        return URL_FIXES[name_lower]
    return name_lower.replace(" ", "").replace("'", "").replace(".", "")

def get_roles_set(role_str):
    """ 'Jungler, Top' -> {'jungler', 'top'} """
    if not role_str: return set()
    parts = role_str.split(',')
    return set(p.strip().lower() for p in parts)

def extract_win_rate_from_script(soup):
    """
    HTML iÃ§indeki JavaScript kodunu tarar.
    {data: 45.7, color: window['wggreen']...} yapÄ±sÄ±nÄ± arar.
    En gÃ¼venilir yÃ¶ntem budur.
    """
    if not soup: return None

    # 1. YÃ¶ntem: Script iÃ§inden Regex ile Ã§ek (En SaÄŸlamÄ±)
    scripts = soup.find_all("script")
    for script in scripts:
        if script.string and "graphDD2" in script.string:
            # Regex: 'wggreen' rengi genellikle "Kazanma" rengidir.
            # {data: 52.2, color: window['wggreen']...}
            match = re.search(r"\{data:\s*(\d+\.?\d*),\s*color:\s*window\['wggreen'", script.string)
            if match:
                return float(match.group(1))

    # 2. YÃ¶ntem: Div iÃ§indeki metni kontrol et (Yedek)
    graph_div = soup.find("div", id="graphDD2")
    if graph_div:
        text = graph_div.get_text().strip()
        match = re.search(r"(\d+\.?\d*)%", text)
        if match:
            return float(match.group(1))
            
    return None

def normalize_scores(matchup_list):
    """
    Verileri 0.1 (En Zor) - 10.0 (En Kolay) arasÄ±na yayar.
    """
    if not matchup_list:
        return []

    # Sadece sayÄ±sal deÄŸerleri al
    wrs = [m['raw_wr'] for m in matchup_list]
    
    if not wrs: return []

    min_val = min(wrs) # Ã–rn: 42.0
    max_val = max(wrs) # Ã–rn: 58.0

    print(f"   ğŸ“Š Ä°statistikler: Min WR: %{min_val} | Max WR: %{max_val}")

    # EÄŸer hepsi aynÄ±ysa (Tek veri varsa veya herkes eÅŸitse)
    if max_val == min_val:
        for m in matchup_list:
            m['score'] = 5.0
            del m['raw_wr']
        return matchup_list

    # Normalizasyon DÃ¶ngÃ¼sÃ¼
    for m in matchup_list:
        val = m['raw_wr']
        
        # FormÃ¼l: 0.1 + (DeÄŸer - Min) / (Max - Min) * 9.9
        normalized = 0.1 + ((val - min_val) / (max_val - min_val)) * 9.9
        
        m['score'] = round(normalized, 2)
        del m['raw_wr'] # Ham veriyi sil, sadece puan kalsÄ±n

    # Puana gÃ¶re sÄ±rala (BÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe - 10.0 en Ã¼ste)
    matchup_list.sort(key=lambda x: x['score'], reverse=True)
    
    return matchup_list

def process_champion(hero, all_champions):
    hero_name = hero['name']
    hero_slug = sanitize_name(hero_name)
    hero_roles = get_roles_set(hero.get('role', ''))
    
    raw_matchups = []
    
    print(f"\nğŸš€ {hero_name} ({hero['role']}) iÅŸleniyor...")
    
    # Rakipleri Filtrele (Rol KesiÅŸimi)
    target_enemies = []
    for c in all_champions:
        if c['name'] == hero_name: continue
        
        enemy_roles = get_roles_set(c.get('role', ''))
        
        # KÃ¼melerin kesiÅŸimi var mÄ±? (Ortak rol var mÄ±?)
        if hero_roles.intersection(enemy_roles):
            target_enemies.append(c)

    total_targets = len(target_enemies)
    print(f"   ğŸ¯ Hedef: {total_targets} rakip ile kÄ±yaslanacak (Rol filtreli).")

    for i, enemy in enumerate(target_enemies):
        enemy_name = enemy['name']
        enemy_slug = sanitize_name(enemy_name)
        
        # KullanÄ±cÄ±nÄ±n verdiÄŸi Ã¶rnek link yapÄ±sÄ±:
        # https://www.leagueofgraphs.com/champions/tier-list/kaisa/vs-aurelionsol/iron
        url = f"https://www.leagueofgraphs.com/champions/tier-list/{hero_slug}/vs-{enemy_slug}/{REGION}"
        
        print(f"\r   [{i+1}/{total_targets}] vs {enemy_name:<15}", end="")
        
        soup = bot.get_soup(url)
        raw_wr = extract_win_rate_from_script(soup)
        
        if raw_wr is not None:
            raw_matchups.append({
                "enemy": enemy_name,
                "raw_wr": raw_wr
            })
        else:
            # Veri Ã§ekilemezse (Site yapÄ±sÄ± deÄŸiÅŸmiÅŸ veya veri yoksa)
            # Pas geÃ§iyoruz, listeye eklemiyoruz.
            pass
        
        # Her istek arasÄ± bekleme
        time.sleep(random.uniform(0.8, 1.5))
    
    print(f"\n   âœ… {hero_name}: {len(raw_matchups)} veri toplandÄ±. Normalizasyon yapÄ±lÄ±yor...")
    
    # Normalizasyon
    final_matchups = normalize_scores(raw_matchups)
    
    return {
        "name": hero_name,
        "role_desc": hero['role'],
        "matchups": final_matchups
    }

def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        champion_list = json.load(f)
    
    # Ä°steÄŸe baÄŸlÄ±: Listeyi isme gÃ¶re sÄ±rala
    champion_list.sort(key=lambda x: x['name'])
    
    for champ in champion_list:
        champ_name = champ['name']
        output_path = os.path.join(OUTPUT_DIR, f"{champ_name}.json")
        
        # Resume (KaldÄ±ÄŸÄ± yerden devam etme) Ã–zelliÄŸi
        if os.path.exists(output_path):
            print(f"â© {champ_name} zaten tamamlanmÄ±ÅŸ, geÃ§iliyor.")
            continue
            
        try:
            data = process_champion(champ, champion_list)
            
            # Kaydet
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=4, ensure_ascii=False)
                
            print("ğŸ’¾ Kaydedildi. SoÄŸuma bekleniyor (3sn)...")
            time.sleep(3)
            
        except Exception as e:
            print(f"\nâŒ Kritik Hata ({champ_name}): {e}")
            time.sleep(5)

if __name__ == "__main__":
    main()
